# Web Scraper & Content Optimizer

A comprehensive 3-phase full-stack application that scrapes articles, optimizes them using AI, and displays them in a beautiful React UI.

## ğŸš€ Features

### Phase 1: Backend API
- âœ… Web scraping of BeyondChats blog articles
- âœ… MongoDB database storage
- âœ… Full CRUD REST API
- âœ… Support for both original and optimized articles

### Phase 2: Content Optimizer
- âœ… Google Search automation with Puppeteer
- âœ… Web scraping of top-ranking articles
- âœ… AI-powered content optimization using Google Gemini
- âœ… Automatic citation and reference tracking
- âœ… Smart content analysis and rewriting

### Phase 3: React Frontend
- âœ… Modern, responsive UI with dark mode
- âœ… Article browsing with search and filtering
- âœ… Detailed article view with formatted content
- âœ… Side-by-side comparison of original vs optimized
- âœ… Premium design with glassmorphism and animations

## ğŸ“ Project Structure

```
web-scraper/
â”œâ”€â”€ backend/                 # Phase 1: Express API & MongoDB
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/         # Database configuration
â”‚   â”‚   â”œâ”€â”€ models/         # Mongoose models
â”‚   â”‚   â”œâ”€â”€ routes/         # API routes
â”‚   â”‚   â”œâ”€â”€ controllers/    # Route controllers
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic (scraper)
â”‚   â”‚   â””â”€â”€ server.js       # Express server
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ content-optimizer/       # Phase 2: AI Content Optimizer
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/       # Google Search, Scraper, LLM, Publisher
â”‚   â”‚   â”œâ”€â”€ utils/          # Logger utility
â”‚   â”‚   â””â”€â”€ index.js        # Main orchestration script
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ (root)/                  # Phase 3: React Frontend
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/     # React components
    â”‚   â”œâ”€â”€ services/       # API client
    â”‚   â”œâ”€â”€ styles/         # CSS styling
    â”‚   â””â”€â”€ App.js          # Main app with routing
    â”œâ”€â”€ package.json
    â”œâ”€â”€ .env
    â””â”€â”€ README.md (this file)
```

## ğŸ› ï¸ Prerequisites

- **Node.js** v14 or higher
- **MongoDB** (local or Atlas)
- **Google Gemini API Key** ([Get one here](https://makersuite.google.com/app/apikey))

## ğŸ“¦ Installation

### 1. Install Backend (Phase 1)

```bash
cd backend
npm install

# Configure environment
cp .env.example .env
# Edit .env and set your MONGODB_URI
```

### 2. Install Content Optimizer (Phase 2)

```bash
cd content-optimizer
npm install

# Configure environment
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 3. Install Frontend (Phase 3)

```bash
cd ..  # Back to root
npm install
```

## ğŸš€ Usage

### Step 1: Start MongoDB

```bash
# If using Docker:
docker run -d -p 27017:27017 --name mongodb mongo:latest

# Or start your local MongoDB instance
```

### Step 2: Start Backend Server

```bash
cd backend
npm run dev
```

Server will start on `http://localhost:5000`

### Step 3: Scrape Initial Articles

```bash
# In a new terminal, make a POST request to scrape articles:
curl -X POST http://localhost:5000/api/articles/scrape

# Or use a REST client like Postman
```

This will scrape 5 articles from BeyondChats blog and store them in MongoDB.

### Step 4: Run Content Optimizer (Optional)

```bash
cd content-optimizer
npm start
```

This will:
1. Fetch original articles from the API
2. Search Google for each article title
3. Scrape top 2 ranking articles
4. Use Gemini AI to optimize the content
5. Publish optimized versions with citations

### Step 5: Start React Frontend

```bash
cd ..  # Back to root
npm start
```

Frontend will start on `http://localhost:3000`

## ğŸ¨ Features Demo

### Article List
- Search articles by title
- Filter by Original/Optimized
- Premium card-based grid layout
- Responsive design for all devices

### Article Detail
- Full formatted article content
- Author and metadata display
- References section for optimized articles
- Link back to original version

### Content Optimization
- AI analyzes top-ranking Google results
- Rewrites content with improved structure
- Maintains factual accuracy
- Adds proper citations

## ğŸ”§ API Endpoints

### Backend API (Port 5000)

- `POST /api/articles/scrape` - Scrape BeyondChats articles
- `GET /api/articles` - Get all articles (supports filtering)
- `GET /api/articles/:id` - Get single article
- `POST /api/articles` - Create article
- `PUT /api/articles/:id` - Update article
- `DELETE /api/articles/:id` - Delete article

### Query Parameters:
- `isOptimized=true|false` - Filter by optimization status
- `page=1` - Page number for pagination
- `limit=10` - Items per page

## ğŸ¯ Environment Variables

### Backend (.env)
```env
MONGODB_URI=mongodb://localhost:27017/beyondchats-scraper
PORT=5000
NODE_ENV=development
```

### Content Optimizer (.env)
```env
GEMINI_API_KEY=your_gemini_api_key_here
BACKEND_API_URL=http://localhost:5000/api
```

### Frontend (.env)
```env
REACT_APP_API_URL=http://localhost:5000/api
```

## ğŸ§ª Testing

### Test Backend API
```bash
# Get all articles
curl http://localhost:5000/api/articles

# Get only optimized articles
curl "http://localhost:5000/api/articles?isOptimized=true"

# Get article by ID
curl http://localhost:5000/api/articles/<article_id>
```

### Test Frontend
1. Open `http://localhost:3000`
2. Verify articles display in grid
3. Test search and filtering
4. Click an article to view details
5. Check responsive design (DevTools)

## ğŸ“ Notes

- The scraper targets 5 specific BeyondChats articles
- Content optimizer processes one article at a time by default
- Puppeteer uses stealth mode to avoid Google detection
- Premium UI design with dark mode and glassmorphism effects
- Fully responsive for mobile, tablet, and desktop

## ğŸ› Troubleshooting

**Backend won't start:**
- Check if MongoDB is running
- Verify MONGODB_URI in .env

**Content Optimizer fails:**
- Verify GEMINI_API_KEY is valid
- Check backend API is running
- Google may block automated searches (use VPN or delays)

**Frontend shows no articles:**
- Verify backend is running on port 5000
- Check REACT_APP_API_URL is correct
- Make sure articles were scraped first

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» Author

Built as a demonstration of modern full-stack development with AI integration.

---

**Stack:**
- Backend: Node.js, Express, MongoDB, Mongoose
- Scraping: Axios, Cheerio, Puppeteer
- AI: Google Gemini API
- Frontend: React, React Router
- Styling: Custom CSS with modern design patterns
